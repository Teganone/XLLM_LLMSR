2025-04-25 18:29:24,892 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.5', qp=True, qp_parser='icl', qp_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', qp_params='temperature=0.2', cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='z3', verifier_model='o3-mini', verifier_params='reasoning_effort=high', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 04:02:15,321 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.5', qp=True, qp_parser='icl', qp_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', qp_params='temperature=0.2', cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.2', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 05:59:23,376 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.5', qp=False, qp_parser='icl', qp_model='gpt-4', qp_params=None, cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.2', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 06:15:27,891 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.5', qp=False, qp_parser='icl', qp_model='gpt-4', qp_params=None, cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.2', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 06:18:17,125 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.5', qp=False, qp_parser='icl', qp_model='gpt-4', qp_params=None, cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.2', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 06:47:28,110 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.6', qp=False, qp_parser='icl', qp_model='gpt-4', qp_params=None, cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.1', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 06:47:48,663 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.6', qp=False, qp_parser='icl', qp_model='gpt-4', qp_params=None, cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.1', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 07:22:29,369 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.8', qp=False, qp_parser='icl', qp_model='gpt-4', qp_params=None, cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.1', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 09:28:14,923 - run_pipeline - INFO - Namespace(input='data/Public_Test_A.json', output='results/Test_A_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.6', qp=True, qp_parser='icl', qp_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', qp_params='temperature=0.3', cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.1', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 13:18:35,708 - run_pipeline - INFO - Namespace(input='data/Final_Selection_Train_v2.json', output='results/Train_o3-mini-high_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='o3-mini', combined_params='reasoning_effort=high', qp=False, qp_parser='icl', qp_model='gpt-4', qp_params=None, cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='o3-mini', verifier_params='reasoning_effort=high', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 15:42:52,097 - run_pipeline - INFO - Namespace(input='data/Final_Selection_Train_v2.json', output='results/Train_llama_0.6_0.3_0.1_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.6', qp=True, qp_parser='icl', qp_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', qp_params='temperature=0.3', cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.1', temperature=0.7, top_p=0.9, max_tokens=1024)
2025-04-26 16:02:15,565 - run_pipeline - INFO - Namespace(input='data/Final_Selection_Train_v2.json', output='results/Train_llama_0.6_0.3_0.1_results.json', config=None, batch_size=10, max_retries=3, combined=True, combined_parser='icl', combined_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', combined_params='temperature=0.6', qp=True, qp_parser='icl', qp_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', qp_params='temperature=0.3', cp=False, cp_parser='icl', cp_model='gpt-4', cp_params=None, verify=True, verifier='llm', verifier_model='/datacenter/models/LLM-Research/Llama-3-8B-Instruct', verifier_params='temperature=0.1', temperature=0.7, top_p=0.9, max_tokens=1024)
