nohup: ignoring input
2025-04-26 17:10:43,950 - finetune - INFO - 加载模型: /datacenter/models/LLM-Research/Llama-3-8B-Instruct
2025-04-26 17:10:44,457 - finetune - INFO - 使用4位量化加载模型
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.89s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.91s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.57s/it]
2025-04-26 17:10:54,341 - finetune - INFO - 模型加载完成
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map: 100%|██████████| 24/24 [00:01<00:00, 12.93 examples/s]Map: 100%|██████████| 24/24 [00:01<00:00, 12.89 examples/s]
2025-04-26 17:11:17,733 - finetune - INFO - 开始训练...
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:06<03:36,  6.19s/it]  6%|▌         | 2/36 [00:11<03:12,  5.65s/it]  8%|▊         | 3/36 [00:16<03:03,  5.55s/it] 11%|█         | 4/36 [00:22<02:56,  5.51s/it] 14%|█▍        | 5/36 [00:27<02:48,  5.45s/it] 17%|█▋        | 6/36 [00:33<02:42,  5.41s/it]                                               17%|█▋        | 6/36 [00:33<02:42,  5.41s/it] 19%|█▉        | 7/36 [00:40<02:52,  5.96s/it] 22%|██▏       | 8/36 [00:45<02:42,  5.79s/it] 25%|██▌       | 9/36 [00:50<02:32,  5.65s/it] 28%|██▊       | 10/36 [00:56<02:24,  5.55s/it] 31%|███       | 11/36 [01:01<02:14,  5.37s/it] 33%|███▎      | 12/36 [01:06<02:08,  5.36s/it]                                                33%|███▎      | 12/36 [01:06<02:08,  5.36s/it] 36%|███▌      | 13/36 [01:14<02:18,  6.03s/it] 39%|███▉      | 14/36 [01:19<02:06,  5.77s/it] 42%|████▏     | 15/36 [01:24<01:58,  5.66s/it] 44%|████▍     | 16/36 [01:30<01:53,  5.70s/it] 47%|████▋     | 17/36 [01:35<01:46,  5.61s/it] 50%|█████     | 18/36 [01:41<01:40,  5.56s/it]                                                50%|█████     | 18/36 [01:41<01:40,  5.56s/it] 53%|█████▎    | 19/36 [01:48<01:43,  6.06s/it] 56%|█████▌    | 20/36 [01:53<01:33,  5.86s/it] 58%|█████▊    | 21/36 [01:59<01:24,  5.67s/it] 61%|██████    | 22/36 [02:04<01:18,  5.58s/it] 64%|██████▍   | 23/36 [02:09<01:11,  5.52s/it] 67%|██████▋   | 24/36 [02:15<01:05,  5.47s/it]                                                67%|██████▋   | 24/36 [02:15<01:05,  5.47s/it] 69%|██████▉   | 25/36 [02:22<01:05,  5.95s/it] 72%|███████▏  | 26/36 [02:27<00:57,  5.80s/it] 75%|███████▌  | 27/36 [02:33<00:51,  5.68s/it] 78%|███████▊  | 28/36 [02:37<00:43,  5.40s/it] 81%|████████  | 29/36 [02:43<00:38,  5.43s/it] 83%|████████▎ | 30/36 [02:48<00:32,  5.42s/it]                                                83%|████████▎ | 30/36 [02:48<00:32,  5.42s/it] 86%|████████▌ | 31/36 [02:55<00:29,  5.89s/it] 89%|████████▉ | 32/36 [03:01<00:22,  5.74s/it] 92%|█████████▏| 33/36 [03:06<00:16,  5.64s/it] 94%|█████████▍| 34/36 [03:11<00:11,  5.57s/it] 97%|█████████▋| 35/36 [03:17<00:05,  5.53s/it]100%|██████████| 36/36 [03:22<00:00,  5.50s/it]                                               100%|██████████| 36/36 [03:22<00:00,  5.50s/it]                                               100%|██████████| 36/36 [03:24<00:00,  5.50s/it]100%|██████████| 36/36 [03:24<00:00,  5.68s/it]
{'loss': 1.0705, 'grad_norm': 0.8602544069290161, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.0}
{'loss': 0.8816, 'grad_norm': 0.7712783217430115, 'learning_rate': 1.5000000000000002e-05, 'epoch': 2.0}
{'loss': 0.749, 'grad_norm': 0.7144079208374023, 'learning_rate': 1.125e-05, 'epoch': 3.0}
{'loss': 0.649, 'grad_norm': 0.6833681464195251, 'learning_rate': 7.500000000000001e-06, 'epoch': 4.0}
{'loss': 0.5801, 'grad_norm': 0.6634930372238159, 'learning_rate': 3.7500000000000005e-06, 'epoch': 5.0}
{'loss': 0.5403, 'grad_norm': 0.644305408000946, 'learning_rate': 0.0, 'epoch': 6.0}
{'train_runtime': 204.5023, 'train_samples_per_second': 0.704, 'train_steps_per_second': 0.176, 'train_loss': 0.745090021027459, 'epoch': 6.0}
2025-04-26 17:14:43,394 - finetune - INFO - 模型已保存到 /datacenter/chendanchun/models/finetune/Llama-3-8B-Instruct_o3-mini-high_combined/final_model
